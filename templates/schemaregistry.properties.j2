# {{ ansible_managed }}
# Copyright 2014 Confluent Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Comma-separated list of listeners that listen for API requests over either HTTP or HTTPS. 
# If a listener uses HTTPS, the appropriate SSL configuration parameters need to be set as well.
# Schema Registry identities are stored in ZooKeeper and are made up of a hostname and port. 
# If multiple listeners are configured, the first listener’s port is used for its identity
listeners=http://0.0.0.0:{{ schema_registry_port }}

# The Avro compatibility type. Valid values are: 
# none (new schema can be any valid Avro schema), 
# backward (new schema can read data produced by latest registered schema), 
# backward_transitive (new schema can read data produced by all previously registered schemas), 
# forward (latest registered schema can read data produced by the new schema), 
# forward_transitive (all previously registered schemas can read data produced by the new schema), 
# full (new schema is backward and forward compatible with latest registered schema), 
# full_transitive (new schema is backward and forward compatible with all previously registered schemas)
avro.compatibility.level={{ schema_avro_compatibility_level }}

# The host name published to ZooKeeper for clients use
host.name={{ hostvars[inventory_hostname]['ec2_private_dns_name'] }}

# A list of Kafka brokers to connect to. For example, PLAINTEXT://hostname:9092,SSL://hostname2:9092
# If this configuration is not specified, the Schema Registry’s internal Kafka clients will get their 
# Kafka bootstrap server list from ZooKeeper (configured with kafkastore.connection.url). 
# Note that if kafkastore.bootstrap.servers is configured, kafkastore.connection.url still needs to be configured, too.
# kafkastore.bootstrap.servers=

# Zookeeper url for the Kafka cluster. If multiple zookeepers are running in the same cluster, 
# all the addresses info should be provided to assure diseaster transfer as a client to cluster
kafkastore.connection.url={{ kafka_zookeeper_connect }}

# The durable single partition topic that acts as the durable log for the data. 
# This topic must be compacted to avoid losing data due to retention policy.

# In order to have a durable kafka store, this item is not configurable to ensure no data loss happened from the start.
kafkastore.topic=_schemas

# The timeout for initialization of the Kafka store, including creation of the 
# Kafka topic that stores schema data.
kafkastore.init.timeout.ms=60000

# Prefix to apply to metric names for the default JMX reporter.
metrics.jmx.prefix=kafka.schema.registry

# The number of samples maintained to compute metrics
metrics.num.samples=2

# The metrics system maintains a configurable number of samples over a fixed window size. 
# This configuration controls the size of the window. For example we might maintain two  
# samples each measured over a 30 second period. When a window expires we erase and overwrite the oldest window.
metrics.sample.window.ms=30000
